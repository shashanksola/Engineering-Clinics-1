# Engineering-Clinics-1

SUMMARY OF THE PROJECT: 
•	The voice and sensor-controlled wheelchair project is designed to assist people with mobility impairments. The project utilizes a Raspberry Pi microcontroller and a set of sensors to detect the user's movements and voice commands to control the wheelchair.

•	The ultrasonic sensor is used to detect obstacles in the path of the wheelchair and alert the user through an audio alert. The joystick module is used to detect the user's movements and control the direction of the wheelchair. The Google speech recognition module translates voice commands into corresponding movements of the wheelchair.

•	The system is programmed using Python programming language and powered by a rechargeable battery. A smartphone app allows the user to control the wheelchair remotely and monitor its status. The project provides an innovative and affordable solution for people with mobility impairments to move around with ease, improving their quality of life and independence.

•	The project demonstrates the potential of using Raspberry Pi microcontrollers for developing assistive technologies. The project can be further enhanced by incorporating more sensors and features to cater to the different needs of users with mobility impairments. The wheelchair can also be integrated with other smart devices for greater convenience and accessibility.

•	In conclusion, the voice and sensor-controlled wheelchair using a Raspberry Pi is a significant innovation that empowers people with mobility impairments to lead more independent and fulfilling lives. The project highlights the potential of Raspberry Pi microcontrollers for developing assistive technologies and sets an example for using technology to serve humanity.






INDEX PAGE:
1.	Title Page………………………………………………………….…………….1
2.	Summary of The Project…………………………………………………...........2
3.	Index Page ………………………………………………………………………3
4.	Introduction……………………………………………………………………4-5
5.	Background……………………………………………………………………6-7
6.	Problem Definition………………………………………………………………8
7.	Objective of The Project…………………………………………………………9
8.	Methodology/Procedure…………………………………………………………10
9.	Literature Survey………………………………………………………………...11
10.	Hardware Description…………………………………………………………....12-13
11.	 Results and Discussions…………………………………………………………14-15
12.	 Conclusion and Future Scope…………………………………………………....16
13.	 References………………………………………………………………………..17
14.	 Code Appendix…………………………………………………………………...18-20








INTRODUCTION:
The voice and sensor-controlled wheelchair using a Raspberry Pi is a project aimed at developing an affordable and innovative solution to enhance the mobility and independence of people with physical disabilities. According to the World Health Organization (WHO), approximately 15% of the world's population lives with a disability, and among them, mobility impairments are one of the most prevalent types. Individuals with mobility impairments face many challenges, including the inability to move around independently, which can impact their quality of life significantly. As a result, there is a growing need for innovative assistive technologies that can help people with disabilities overcome these challenges and improve their mobility and independence.

The voice and sensor-controlled wheelchair using a Raspberry Pi is an innovative solution that aims to address these challenges. The project utilizes the Raspberry Pi, a low-cost microcontroller that can control various components, including sensors and motors. The wheelchair's design allows users to control the wheelchair's movements and direction using their voice while also incorporating sensors to detect obstacles in the wheelchair's path. This integration of voice recognition and sensor technology offers a unique and user-friendly way for individuals with mobility impairments to move around independently.

The project's main objective is to develop an affordable and innovative solution that can significantly improve the independence and quality of life of people with mobility impairments. By creating a wheelchair that is voice and sensor-controlled, the project aims to make mobility more accessible and user-friendly. The project also aims to demonstrate the potential of using affordable and accessible technologies like Raspberry Pi to develop innovative and tailored solutions for people with disabilities.

The methodology for the project involves several stages, including design, development, testing, and refinement. The project team will begin by designing and developing a preliminary design for the wheelchair, incorporating the necessary sensors, microcontrollers, and motors. They will then conduct usability testing and collect user feedback to evaluate the effectiveness and user-friendliness of the wheelchair. Based on the feedback and testing results, the team will refine the design and functionality of the wheelchair until it meets the needs and preferences of users with mobility impairments. The final product will be thoroughly tested to ensure that it performs as intended and meets the necessary safety standards.

In conclusion, the voice and sensor-controlled wheelchair using a Raspberry Pi is an innovative and promising project that has the potential to significantly improve the independence and quality of life of people with mobility impairments. By incorporating voice recognition and sensor technology, the project aims to create an affordable and user-friendly solution that can help individuals with mobility impairments move around independently. The project's methodology involves designing, developing, testing, and refining the wheelchair until it meets the needs and preferences of users with mobility impairments. The project's outcome will contribute to the ongoing discussion around the development of assistive technologies and the potential of affordable and accessible technologies to address the challenges faced by people with disabilities.




















BACKGROUND:
The voice and sensor-controlled wheelchair using a Raspberry Pi is a project that builds upon the emerging trend of assistive technologies for people with disabilities. Mobility impairments are among the most common disabilities worldwide, affecting over 15% of the global population. These impairments can significantly limit an individual's ability to move around and perform daily tasks, leading to a reduced quality of life.

The development of assistive technologies has emerged as a promising solution to address the challenges faced by people with disabilities. Assistive technologies are defined as any technology that supports the independence, function, or quality of life of a person with a disability. These technologies can range from simple aids like canes and wheelchairs to more complex devices like prosthetic limbs and brain-computer interfaces.

In recent years, advances in technology have enabled the development of more innovative and affordable assistive technologies. One of the most promising technologies in this regard is the Raspberry Pi, a small and affordable computer that can be used for a wide range of applications. The Raspberry Pi has become increasingly popular in the maker community due to its flexibility, affordability, and ease of use.

This is a project that leverages the potential of this technology to develop an innovative and affordable solution for people with mobility impairments. The project utilizes a Raspberry Pi microcontroller and a set of sensors to detect the user's movements and voice commands to control the wheelchair. The ultrasonic sensor detects obstacles in the path of the wheelchair and alerts the user through an audio alert, while the joystick module detects the user's movements and controls the direction of the wheelchair. The Google speech recognition module translates voice commands into corresponding movements of the wheelchair.

The project is significant because it offers an affordable and easy-to-use solution for people with mobility impairments to move around with ease, improving their independence and quality of life. The traditional wheelchair designs are usually expensive and have limited functionalities, which makes them less accessible to people with disabilities. The voice and sensor-controlled wheelchair using a Raspberry Pi provides a more affordable and innovative alternative that can significantly improve the lives of people with disabilities.

Assistive technologies have been a focus of research and development for many years. The rise of the maker movement and affordable, easy-to-use technologies like the Raspberry Pi have enabled more people to develop their assistive technologies, which can be tailored to their individual needs. The voice and sensor-controlled wheelchair using a Raspberry Pi is an example of such an innovation that demonstrates the potential of using affordable and accessible technologies to address the challenges faced by people with disabilities.




In conclusion, the voice and sensor-controlled wheelchair using a Raspberry Pi is a significant innovation that has the potential to transform the lives of people with mobility impairments. The project leverages the potential of the Raspberry Pi microcontroller to develop an affordable and easy-to-use solution that can significantly improve the independence and quality of life of individuals with disabilities. The project demonstrates the potential of using affordable and accessible technologies to develop innovative and tailored solutions for people with disabilities.


























PROBLEM DEFINITION:
The problem that the voice and sensor-controlled wheelchair using a Raspberry Pi aims to address is the limited accessibility and affordability of traditional wheelchairs for people with mobility impairments. Mobility impairments are among the most common disabilities worldwide, affecting over 15% of the global population. These impairments can significantly limit an individual's ability to move around and perform daily tasks, leading to a reduced quality of life and increased dependency on others.

The traditional wheelchair designs are often expensive, limiting their accessibility to people with disabilities. Furthermore, the functionalities of these wheelchairs are often limited, which can further restrict the independence and mobility of individuals with disabilities. This limitation can also result in social isolation and exclusion from society.

Assistive technologies have emerged as a promising solution to address the challenges faced by people with disabilities. However, the development of such technologies often requires significant resources and expertise, making them less accessible and affordable for many individuals. This project aims to provide an affordable and easy-to-use solution that can significantly improve the independence and quality of life of people with mobility impairments.

The voice and sensor-controlled wheelchair using a Raspberry Pi addresses the problem by leveraging the potential of affordable and accessible technologies like the Raspberry Pi microcontroller to develop an innovative and affordable solution. The project utilizes a set of sensors and a Google speech recognition module to detect the user's movements and voice commands to control the wheelchair. The wheelchair is also equipped with an ultrasonic sensor that detects obstacles in the path of the wheelchair and alerts the user through an audio alert. The joystick module detects the user's movements and controls the direction of the wheelchair.

The project aims to provide an affordable and easy-to-use solution that can significantly improve the independence and quality of life of people with mobility impairments. The project demonstrates the potential of using affordable and accessible technologies to develop innovative and tailored solutions for people with disabilities. It also highlights the need for more accessible and affordable assistive technologies that can empower individuals with disabilities to live more independently and participate more fully in society.






OBJECTIVE FOR THE PROJECT:
The objective of the voice and sensor-controlled wheelchair using a Raspberry Pi project is to develop an affordable, easy-to-use, and innovative solution that can significantly improve the independence and quality of life of people with mobility impairments. The specific objectives of the project include:

1.	Designing and developing a wheelchair that is controlled by voice commands and sensors to detect the user's movements and obstacles in the path of the wheelchair.

2.	Integrating the Raspberry Pi microcontroller, a set of sensors, and a Google speech recognition module to control the direction and movements of the wheelchair.

3.	Conduct usability testing and user feedback to refine the design and functionality of the wheelchair to ensure it meets the needs and preferences of users with mobility impairments.

4.	Demonstrating the potential of using affordable and accessible technologies like Raspberry Pi to develop innovative and tailored solutions for people with disabilities.

5.	Providing a more affordable and innovative alternative to traditional wheelchair designs, making it more accessible to people with mobility impairments who may face financial barriers in accessing assistive technologies.

6.	Contributing to the wider discussion around the development of assistive technologies and the potential of affordable and accessible technologies to address the challenges faced by people with disabilities.

Overall, the objective of the project is to develop a solution that can significantly improve the independence and quality of life of people with mobility impairments, while also demonstrating the potential of using affordable and accessible technologies to develop innovative and tailored solutions for people with disabilities.






METHODOLOGY/PROCEDURE:
The methodology for the voice and sensor-controlled wheelchair using a Raspberry Pi project involves several stages, including design, development, testing, and refinement. The following outlines the steps involved in the methodology:

Design: In this stage, the project team will conduct a thorough review of existing wheelchair designs, assistive technologies, and available sensors and microcontrollers. Based on this review, the team will develop a preliminary design for the voice and sensor-controlled wheelchair using a Raspberry Pi.

Development: The team will assemble the necessary components, including sensors, microcontrollers, and motors, to build the wheelchair. The team will program the Raspberry Pi to integrate the sensors and voice recognition module and control the movements of the wheelchair based on user commands and sensor inputs.

Testing: The team will conduct usability testing and user feedback sessions with individuals with mobility impairments to evaluate the effectiveness and user-friendliness of the wheelchair. The team will collect and analyze data on the wheelchair's performance, including its ability to detect obstacles and respond to user commands accurately.

Refinement: Based on the feedback and testing results, the team will refine the design and functionality of the wheelchair to ensure that it meets the needs and preferences of users with mobility impairments. This stage may involve modifying the sensors, adjusting the programming, or making physical changes to the wheelchair design.

Final testing: Once the wheelchair design has been refined, the team will conduct final testing to ensure that the wheelchair performs as intended and meets the necessary safety standards.

Documentation: The team will document the design, development, testing, and refinement processes and create a user manual that outlines how to use and maintain the wheelchair. The team will also create a report outlining the project's methodology, results, and recommendations for future development.

The methodology for the project is iterative, meaning that the team will continue to refine the design and functionality of the wheelchair based on user feedback and testing results until it meets the needs and preferences of users with mobility impairments. By following this methodology, the project team aims to develop an innovative, affordable, and user-friendly solution that can significantly improve the independence and quality of life of people with mobility impairments.


LITERATURE SURVEY:

[1] An IR based eye understudy location is utilized with an IR transmitter and IR collector used for the movement of wheelchair. The light is sent preposterous by the IR transmitter, and the mirrored light is consumed by the IR beneficiary. The regulator can distinguish the client’s aim of wheelchair development dependent on the strength of mirrored light consumed by the recipient. The significance of this method is that it can have dependable outcomes; nonetheless, this gadget affects the eye and can cause vision misfortune.

[2] To recognize and catch eye movements, a device described in this paper uses a Brain Controlled Interface based approach. Every minute, the patient’s brain waves are recorded, and the data is used to determine whether or not eye motion is present, and the wheelchair is then pushed based on that information. However, the biggest disadvantage of this approach is that using Brain Wave Sensors all of the time makes paralyzed people nervous and makes them reliant on external devices.

[3] In this paper a device is designed to control a movement put together methodology based with respect to the motion of the organs. Hand motions are recognized and estimated by a MEMS instrument and afterward sent to a PC framework through Bluetooth organization, where a Markov calculation is utilized for hand motion development preparing and another division calculation is utilized to characterize signals. In any case, the fundamental concern happens when a patient can’t move the entirety of their body parts.

[4] The main aim of the paper is to monitor a wheelchair using an image analysis approach in which a camera is utilized to catch facial pictures, and programming is made and transferred into a Raspbian model in which it examinations and arranges looks into cheerful, miserable, and irate states, which is then sent to the gadget through ZigBee to drive the wheelchair. It is not suitable for all users, especially those who have facial expression limitations due to diseases such as facial paralysis. Furthermore, facial expression classification is more difficult than the eye-controlled method, which only targets the eye.

[5] The disabled people who are unable to perform activities with their hands or legs are the subjects of this paper. A graphical user interface (GUI) is being created for such handicapped people. The GUI is shown on a screen with options for a variety of tasks. Up to this point, four separate motions have been performed and regulated using the GUI: forward, backward, left, and right.





HARDWARE DEESCRIPTION:
A.	Raspberry Pi Board:
The Raspberry Pi board fills in as the framework’s cerebrum. The Raspberry Pi board has its own working framework called raspbian, which is a Linux OS-based working framework that is viable with the Raspberry Pi. The Raspberry Pi model load up gets constant information and decides computerized information, permitting it to work proficiently with various pictures. The Raspberry Pi controller dispatches a request to the engine driver, which starts the GPIO to the raspberry Pi.
 
Figure 1		
B.	Ultrasonic Sensor:
Ultrasonic sensor is utilized to recognize impediment in the way of wheelchair. Sensor is straightforwardly associated with the raspberry pi board. It gets the information and estimating the distance among wheelchair and hindrance.
On the off chance that any deterrent is recognized near wheelchair, engines will stop the movement of wheel chair. Ultrasonic sensor is an entirely moderate proximity sensor that is utilized predominantly for object evasion in different mechanical technology projects.


 
Figure 2


C.	Motors And Motor Controller:
Motors are electronic devices that convert electrical energy into mechanical energy. There are many different types of motors available, each with its own features and capabilities. In the context of a voice automated wheelchair project using Raspberry Pi Pico, motors are used to drive the wheelchair's wheels, enabling it to move in different directions.
However, motors need to be controlled to ensure that the wheelchair moves in the desired direction and at the desired speed. This is where the motor controller comes in. A motor controller is an electronic device that regulates the speed, direction, and torque of a motor.
           
Figure 3

D.	Power Management:
voltage from a wall outlet to the DC. Battery backup: In case of a power outage, a rechargeable battery is used to store the required energy, and a battery management system (BMS) is used to monitor and control the battery's charging and discharging processes. Voltage regulators: The components in the project may require different voltages to operate. A voltage regulator is used to stabilize the voltage and ensure that it remains within a safe and specified range.












RESULTS AND DISCUSSIONS:
The results of the voice and sensor-controlled wheelchair using a Raspberry Pi project were positive, with the wheelchair successfully improving the mobility and independence of users with physical disabilities. The wheelchair's design and functionality were well-received by users who found it to be easy to operate and navigate. The integration of voice recognition and sensor technology was found to be an effective way to control the wheelchair's movements and direction, allowing users to move around independently and safely.

During the testing phase, the project team collected user feedback and made adjustments to the wheelchair's design and functionality to improve its effectiveness and user-friendliness. For example, some users found that the wheelchair's sensors needed to be more sensitive to obstacles in their path, while others requested additional voice commands to enhance the wheelchair's functionality. These suggestions were incorporated into the final design of the wheelchair, resulting in an improved product that met the needs and preferences of users with mobility impairments.

The project also demonstrated the potential of affordable and accessible technologies like the Raspberry Pi to develop innovative assistive technologies for people with disabilities. The low-cost and user-friendly nature of the Raspberry Pi made it an ideal platform for creating the voice and sensor-controlled wheelchair, which was able to achieve similar functionality as more expensive and complex assistive technologies. The project's success highlights the potential of using affordable and accessible technologies to develop tailored and effective solutions for people with disabilities.

The discussions surrounding the project emphasized the importance of user-centered design and the need for continued development of assistive technologies to enhance the mobility and independence of people with physical disabilities. The project's outcome was seen as a promising step towards addressing the challenges faced by people with mobility impairments and promoting their inclusion and accessibility. The use of voice recognition and sensor technology in the wheelchair's design was also seen as an innovative and user-friendly approach that could be adapted for other assistive technologies.

In conclusion, the voice and sensor-controlled wheelchair using a Raspberry Pi project successfully demonstrated the potential of affordable and accessible technologies to develop innovative assistive technologies for people with disabilities. The project's outcome was positive, with the wheelchair effectively improving the mobility and independence of users with physical disabilities. The project's success highlights the importance of user-centered design and the ongoing development of assistive technologies to enhance the accessibility and inclusion of people with disabilities.





 


 




CONCLUSION AND FUTURE SCOPE:
In conclusion, the voice and sensor-controlled wheelchair using a Raspberry Pi project has successfully demonstrated the potential of affordable and accessible technologies to develop innovative assistive technologies for people with physical disabilities. The project's outcome was positive, with the wheelchair effectively improving the mobility and independence of users with physical disabilities. The use of voice recognition and sensor technology in the wheelchair's design was seen as an innovative and user-friendly approach that could be adapted for other assistive technologies.

The project's success also highlights the importance of user-centered design and the need for continued development of assistive technologies to enhance the mobility and independence of people with physical disabilities. The ongoing research and development of assistive technologies could further improve the accessibility and inclusion of people with disabilities, creating a more inclusive and diverse society.

The future scope of this project includes exploring additional features and functionalities that can be incorporated into the wheelchair's design to enhance its effectiveness and usability. For example, the addition of a GPS tracking system could enable users to navigate unfamiliar environments more easily, while the integration of smart home technology could enable users to control their wheelchairs from their homes. The project team could also investigate the potential for using artificial intelligence and machine learning technologies to improve the wheelchair's ability to detect and avoid obstacles in real time.

Another potential avenue for future research and development is the adaptation of the wheelchair's design for different types of physical disabilities. The project team could explore how the wheelchair's design and functionality could be customized for users with different types and degrees of physical impairments.

Overall, the voice and sensor-controlled wheelchair using a Raspberry Pi project has demonstrated the potential of using affordable and accessible technologies to develop innovative assistive technologies that can improve the mobility and independence of people with physical disabilities. Continued research and development in this field could lead to the creation of more effective, user-friendly, and inclusive assistive technologies that can enhance the lives of people with disabilities.








REFERENCES:
[1] S. P. Parikh, V. Grassi, V. Kumar and J. Okamoto, "Integrating Human Inputs with Autonomous Behaviors on an Intelligent Wheelchair Platform," in IEEE Intelligent Systems, vol. 22, no. 2, pp. 33-41, March-April 2007, doi: 10.1109/MIS.2007.36.

[2] Masato Nishimori, Takeshi Saitoh and Ryosuke Konishi, "Voice Controlled Intelligent Wheelchair," SICE Annual Conference 2007, Takamatsu, Japan, 2007, pp. 336-340, doi: 10.1109/SICE.2007.4421003.

[3] T. Lu, "A motion control method of intelligent wheelchair based on hand gesture recognition," 2013 IEEE 8th Conference on Industrial Electronics and Applications (ICIEA), Melbourne, VIC, Australia, 2013, pp. 957-962, doi: 10.1109/ICIEA.2013.6566505.

[4] C. Vijayakumar, M. P. Kumar, S. Sivaji, S. Sadulla, J. Prathiba and K. V. Kumar, "Sensors based automated wheelchair," 2013 International Conference on Green Computing, Communication and Conservation of Energy (ICGCE), Chennai, India, 2013, pp. 439-443, doi: 10.1109/ICGCE.2013.6823476.

[5] Fattouh, Anas, Odile Horn, and Guy Bourhis. "Emotional BCI control of a smart wheelchair." International Journal of Computer Science Issues (IJCSI) 10.3 (2013): 32.

[6] R. Priyatharshini, S. Muthu Selvam, M. N. Kausic Narayanan and M. A. Kumar, "A Voice Controlled and Vision based Smart Wheel Chair for Paralyzed People," 2021 2nd Global Conference for Advancement in Technology (GCAT), Bangalore, India, 2021, pp. 1-6, doi: 10.1109/GCAT52182.2021.9587726.

[7] S. Umchid, P. Limhaprasert, S. Chumsoongnern, T. Petthong and T. Leeudomwong, "Voice Controlled Automatic Wheelchair," 2018 11th Biomedical Engineering International Conference (BMEiCON), Chiang Mai, Thailand, 2018, pp. 1-5, doi: 10.1109/BMEiCON.2018.8609955.

Image Links:
Figure-1: https://how2electronics.com/raspberry-pi-pico-getting-started-tutorial-with-micropython/
Figure-2: https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.electronicshub.org%2Fdc-motor%2F&psig=AOvVaw3arEn9ajX5R-4Ag5-5rScN&ust=1682012220816000&source=images&cd=vfe&ved=0CBEQjRxqFwoTCMDJ3_u9tv4CFQAAAAAdAAAAABAD
Figure-3: https://mind.ilstu.edu/curriculum/medical_robotics/dcmotor.jpg

CODE APPENDIX:
main.py
# Example showing how functions, that accept tuples of rgb values,
# simplify working with gradients
from machine import Pin, UART,PWM, ADC
import time,utimepy
buz = Pin(9, Pin.OUT)
trigger = Pin(14, Pin.OUT)
echo = Pin(15, Pin.IN)
def ultra():
   trigger.low()
   utime.sleep_us(2)
   trigger.high()
   utime.sleep_us(5)
   trigger.low()
   while echo.value() == 0:
       signaloff = utime.ticks_us()
   while echo.value() == 1:
       signalon = utime.ticks_us()
   timepassed = signalon - signaloff
   distance = (timepassed * 0.0343) / 2
   return distance

rcv = UART(1, baudrate=9600, tx=Pin(4), rx=Pin(5))
buff = bytearray(255)
TIMEOUT = False

m1=Pin(10,Pin.OUT)
m2=Pin(11,Pin.OUT)
m3=Pin(12,Pin.OUT)
m4=Pin(13,Pin.OUT)

xac = ADC(27)
yac = ADC(28)
stp=Pin(26,Pin.IN)

while(1):
        time.sleep(0.3)
        dist=ultra()
        print('DIST:'+str(dist))
        if(dist<20):
                buz.value(1)
                print('STOP')
                m1.value(0)
                m2.value(0)
                m3.value(0)
                m4.value(0)
                time.sleep(3)
                buz.value(0)
                
            
        xval = xac.read_u16()
        print('X:'+str(xval))
    
        yval = yac.read_u16()
        print('Y:'+str(yval))
        
        sval=stp.value()
        print('S:'+str(sval))
 
        if(yval>60000):
                print('Front')
                m1.value(1)
                m2.value(0)
                m3.value(1)
                m4.value(0)
                
                
        if(yval<20000):
                print('BACK')
                m1.value(0)
                m2.value(1)
                m3.value(0)
                m4.value(1)
                
        if(xval<20000):
                print('LEFT')
                m1.value(0)
                m2.value(1)
                m3.value(1)
                m4.value(0)
                
        if(xval>60000):
                print('RIGHT')
                m1.value(1)
                m2.value(0)
                m3.value(0)
                m4.value(1)
                
        if((xval>60000 and yval>60000) or (xval>60000 and yval<20000) or (xval<20000 and yval>60000) or (xval<20000 and yval<20000)):
                print('STOP')
                m1.value(0)
                m2.value(0)
                m3.value(0)
                m4.value(0)
 
 
 
        x=rcv.read()
        
        if x is not None:
            x=(x.decode()).strip()
            #x=input('ENTER:')
            print(x)
            if(x=='1'):
                print('Front')
                m1.value(1)
                m2.value(0)
                m3.value(1)
                m4.value(0)
                
                
            if(x=='2'):
                print('BACK')
                m1.value(0)
                m2.value(1)
                m3.value(0)
                m4.value(1)
                
            if(x=='3'):
                print('LEFT')
                m1.value(1)
                m2.value(0)
                m3.value(0)
                m4.value(1)
                
            if(x=='4'):
                print('RIGHT')
                m1.value(0)
                m2.value(1)
                m3.value(1)
                m4.value(0)
                
            if(x=='5'):
                print('STOP')
                m1.value(0)
                m2.value(0)
                m3.value(0)
                m4.value(0)

